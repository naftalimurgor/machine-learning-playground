{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Association rule learning is a type of unsupervised learning that identifies interesting relations between variables in large databases. It is intended to identify strong rules discovered in databases using some measures of interestingness. In any given transaction with a variety of items, association rules are meant to discover the rules that determine how or why certain items are connected.\n",
        "\n",
        "The Apriori algorithm is a popular algorithm for association rule learning. The Apriori algorithm works by first finding all frequent item sets in the transaction database. It then uses a confidence measure to associate these item sets with each other. The confidence measure is a probability that two items will occur together in a transaction.\n",
        "\n",
        "The Apriori algorithm works by using a candidate generation and candidate elimination process. In the candidate generation process, the Apriori algorithm generates all possible item sets of a given size. In the candidate elimination process, the Apriori algorithm checks each item set to see if it occurs frequently enough in the transaction database.\n",
        "\n",
        "The Apriori algorithm has a number of advantages, including:\n",
        "\n",
        "It is efficient in finding frequent item sets.\n",
        "It is able to handle large datasets.\n",
        "It is able to find association rules with high confidence.\n",
        "The Apriori algorithm also has a number of disadvantages, including:\n",
        "\n",
        "It can be computationally expensive to find all frequent item sets.\n",
        "It can be difficult to interpret the results of association rule learning.\n",
        "It can be sensitive to noise in the data.\n",
        "Here is a dataset that can be used for association rule learning:"
      ],
      "metadata": {
        "id": "b_7uLNassnUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        " \n",
        " The code provided aims to mine association rules from a transaction dataset. The dataset consists of transactions recorded over a specific period of time and includes the following columns:\n",
        "\n",
        "id: Represents the unique identifier for each transaction.\n",
        "transaction_date: Indicates the date when the transaction occurred.\n",
        "transaction_amount: Represents the amount spent in the transaction.\n",
        "merchant_name: Specifies the name of the merchant where the transaction took place.\n",
        "category: Represents the category or type of the transaction, such as \"Groceries\", \"Coffee\", \"Streaming\", etc.\n",
        "The code performs the following steps:\n",
        "\n",
        "It loads the transaction dataset from a CSV file.\n",
        "Preprocesses the transaction data, converting it into a suitable format for further analysis.\n",
        "Applies the Apriori algorithm to identify frequent itemsets, which are sets of items (in this case, categories) that appear together frequently in the transactions.\n",
        "Generates association rules from the frequent itemsets. Association rules indicate relationships between different categories and provide insights into potential purchasing patterns.\n",
        "Prints the discovered frequent itemsets and association rules for analysis and interpretation.\n",
        "By running this code with the given dataset, you can uncover associations between different transaction categories, such as identifying which categories tend to occur together frequently or which categories are likely to be associated with specific merchants. This information can be valuable for various applications, including market basket analysis, recommendation systems, and targeted marketing strategies."
      ],
      "metadata": {
        "id": "Q-5NqaKI7Pdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary modules and functions (os, pandas, TransactionEncoder, apriori, association_rules) for data processing and association rule mining.\n"
      ],
      "metadata": {
        "id": "yit5EpxC5hNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import apriori, association_rules"
      ],
      "metadata": {
        "id": "GcaP9lGO58jO"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Get the current working directory using os.getcwd().\n"
      ],
      "metadata": {
        "id": "tAviYK-l5oRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Get the current working directory\n",
        "current_directory = os.getcwd()"
      ],
      "metadata": {
        "id": "oLA5NN_w6APt"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Join the current directory path with the CSV file name to create the file path.\n"
      ],
      "metadata": {
        "id": "3TPZSWLv5qB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Join the current directory with the CSV file name\n",
        "csv_file_path = os.path.join(current_directory, 'transaction_data.csv')"
      ],
      "metadata": {
        "id": "w63gW_Wx6DRN"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Load the CSV file using Pandas and store the data in the transaction_data variable.\n"
      ],
      "metadata": {
        "id": "2Q-wdyD35riR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Load the CSV file using Pandas\n",
        "transaction_data = pd.read_csv(csv_file_path)"
      ],
      "metadata": {
        "id": "matzrEzn6Ish"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Convert the transaction data to a list format using .values.tolist(). This step prepares the data for further processing.\n"
      ],
      "metadata": {
        "id": "zlZWVg2L5tAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Preprocess the transaction data\n",
        "transaction_list = transaction_data.values.tolist()"
      ],
      "metadata": {
        "id": "lnvksMxu6Kch"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Convert each item in the transaction data to a string format. This is necessary to ensure all items are in a consistent format for the TransactionEncoder to handle.\n"
      ],
      "metadata": {
        "id": "bkSfEuQO5uO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Convert the transaction data to a string format\n",
        "transaction_list = [[str(item) for item in transaction] for transaction in transaction_list]"
      ],
      "metadata": {
        "id": "pxXkxqqb6MYw"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Create an instance of TransactionEncoder and encode the transaction data into a binary matrix using te.fit_transform(). This step transforms the transaction data into a format suitable for the Apriori algorithm.\n"
      ],
      "metadata": {
        "id": "Lmf9_cBX5vtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Encode the transaction data into a binary matrix\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit_transform(transaction_list)\n",
        "transaction_df = pd.DataFrame(te_ary, columns=te.columns_)"
      ],
      "metadata": {
        "id": "JVP6g3aK6QDQ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Apply the Apriori algorithm to find frequent itemsets using apriori(). Specify the minimum support threshold (min_support) and set use_colnames=True to use column names from the transaction data."
      ],
      "metadata": {
        "id": "IpxQfhTj5y1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Apply the Apriori algorithm to find frequent itemsets\n",
        "frequent_itemsets = apriori(transaction_df, min_support=0.1, use_colnames=True)"
      ],
      "metadata": {
        "id": "DXcEI_zj6Ttf"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Generate association rules from the frequent itemsets using association_rules(). Specify the desired metric for rule evaluation (metric) and set the minimum threshold for the metric (min_threshold)."
      ],
      "metadata": {
        "id": "AcgeG5Y_6Zuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Generate association rules from the frequent itemsets\n",
        "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)"
      ],
      "metadata": {
        "id": "1DQWAiES6mr9"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the frequent itemsets using print(frequent_itemsets)."
      ],
      "metadata": {
        "id": "VvvrZZrr6bl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Print the frequent itemsets and association rules\n",
        "print(\"Frequent Itemsets:\")\n",
        "print(frequent_itemsets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCzDGAtj6j7N",
        "outputId": "83c91029-1b7d-4196-f6ad-c92850e2331b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent Itemsets:\n",
            "     support                                itemsets\n",
            "0        0.2                                     (1)\n",
            "1        0.2                                    (10)\n",
            "2        0.2                                   (100)\n",
            "3        0.2                                     (2)\n",
            "4        0.2                                    (20)\n",
            "..       ...                                     ...\n",
            "146      0.2  (Groceries, Walmart, 6/6/2023, 1, 100)\n",
            "147      0.2     (6/6/2023, Gas, 4, Gas Station, 10)\n",
            "148      0.2    (Coffee, 6/6/2023, Starbucks, 2, 50)\n",
            "149      0.2   (6/6/2023, 3, Netflix, Streaming, 20)\n",
            "150      0.2     (5, 6/6/2023, Shopping, Amazon, 30)\n",
            "\n",
            "[151 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the association rules using print(rules)."
      ],
      "metadata": {
        "id": "wYoaapxA6dia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nAssociation Rules:\")\n",
        "print(rules)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5Lagl036hpw",
        "outputId": "e4f76de1-1aac-479a-8220-9dc9d702a2bd"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Association Rules:\n",
            "      antecedents                       consequents  antecedent support  \\\n",
            "0             (1)                             (100)                 0.2   \n",
            "1           (100)                               (1)                 0.2   \n",
            "2             (1)                        (6/6/2023)                 0.2   \n",
            "3     (Groceries)                               (1)                 0.2   \n",
            "4             (1)                       (Groceries)                 0.2   \n",
            "..            ...                               ...                 ...   \n",
            "820  (Amazon, 30)           (5, Shopping, 6/6/2023)                 0.2   \n",
            "821           (5)  (Amazon, Shopping, 30, 6/6/2023)                 0.2   \n",
            "822    (Shopping)         (Amazon, 5, 30, 6/6/2023)                 0.2   \n",
            "823      (Amazon)       (5, 30, Shopping, 6/6/2023)                 0.2   \n",
            "824          (30)   (Amazon, 5, Shopping, 6/6/2023)                 0.2   \n",
            "\n",
            "     consequent support  support  confidence  lift  leverage  conviction  \n",
            "0                   0.2      0.2         1.0   5.0      0.16         inf  \n",
            "1                   0.2      0.2         1.0   5.0      0.16         inf  \n",
            "2                   1.0      0.2         1.0   1.0      0.00         inf  \n",
            "3                   0.2      0.2         1.0   5.0      0.16         inf  \n",
            "4                   0.2      0.2         1.0   5.0      0.16         inf  \n",
            "..                  ...      ...         ...   ...       ...         ...  \n",
            "820                 0.2      0.2         1.0   5.0      0.16         inf  \n",
            "821                 0.2      0.2         1.0   5.0      0.16         inf  \n",
            "822                 0.2      0.2         1.0   5.0      0.16         inf  \n",
            "823                 0.2      0.2         1.0   5.0      0.16         inf  \n",
            "824                 0.2      0.2         1.0   5.0      0.16         inf  \n",
            "\n",
            "[825 rows x 9 columns]\n"
          ]
        }
      ]
    }
  ]
}